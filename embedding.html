
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Network embedding &#8212; Network Data Science</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="_static/logo.png"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Graph matching" href="graph_matching.html" />
    <link rel="prev" title="Community detection" href="community_detection.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-JYHFQNEPZN"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-JYHFQNEPZN');
                </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Network Data Science</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="landing.html">
                    Welcome
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Course logistics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="syllabus.html">
   Syllabus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="calendar.html">
   Calendar
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mini_assignment.html">
   Mini-assignment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="final_project.html">
   Final project
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="online_resources.html">
   Online
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="books.html">
   Books
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="datasets.html">
   Datasets
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Lectures
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://bdpedigo.github.io/networks-course/welcome.html">
   Welcome
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://bdpedigo.github.io/networks-course/what_are_networks.html">
   What are networks?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="representing_networks.html">
   Representing networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plotting_networks.html">
   Plotting networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="connected_components.html">
   Connected components
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="centrality.html">
   Centrality measures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="random_graphs.html">
   Random network models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="community_detection.html">
   Community detection
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Network embedding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="graph_matching.html">
   Graph matching
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="multiple_embedding.html">
   Embedding multiple networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ranking.html">
   Ranking and flow
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/bdpedigo/networks-course/main?urlpath=tree/docs/embedding.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/bdpedigo/networks-course"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/bdpedigo/networks-course/issues/new?title=Issue%20on%20page%20%2Fembedding.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/bdpedigo/networks-course/edit/main/docs/embedding.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/embedding.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#why-embed-networks">
   Why embed networks?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spectral-methods">
   Spectral methods
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#low-rank-approximation">
     Low-rank approximation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#singular-value-decomposition">
     Singular value decomposition
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#eckart-young-mirsky-theorem">
     Eckart-Young-Mirsky theorem
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#adjacency-spectral-embedding">
     Adjacency Spectral Embedding
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#laplacian-spectral-embedding">
     Laplacian spectral embedding
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#two-truths">
     Two truths
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deepwalk-node2vec">
   DeepWalk / Node2Vec
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#word2vec">
     Word2vec
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#from-word2vec-to-deepwalk">
     From Word2Vec to DeepWalk
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#from-deepwalk-to-node2vec">
     From DeepWalk to Node2Vec
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#running-node2vec">
     Running Node2Vec
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#applications-using-embeddings">
   Applications using embeddings
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recommendation">
     Recommendation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#clustering">
     Clustering
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Network embedding</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#why-embed-networks">
   Why embed networks?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spectral-methods">
   Spectral methods
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#low-rank-approximation">
     Low-rank approximation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#singular-value-decomposition">
     Singular value decomposition
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#eckart-young-mirsky-theorem">
     Eckart-Young-Mirsky theorem
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#adjacency-spectral-embedding">
     Adjacency Spectral Embedding
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#laplacian-spectral-embedding">
     Laplacian spectral embedding
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#two-truths">
     Two truths
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deepwalk-node2vec">
   DeepWalk / Node2Vec
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#word2vec">
     Word2vec
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#from-word2vec-to-deepwalk">
     From Word2Vec to DeepWalk
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#from-deepwalk-to-node2vec">
     From DeepWalk to Node2Vec
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#running-node2vec">
     Running Node2Vec
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#applications-using-embeddings">
   Applications using embeddings
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recommendation">
     Recommendation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#clustering">
     Clustering
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="network-embedding">
<h1>Network embedding<a class="headerlink" href="#network-embedding" title="Permalink to this headline">#</a></h1>
<p>Generally speaking, an <strong>embedding</strong> refers to some technique which takes a network (or
networks as we’ll see later) and converts it to a representation in some vector space.
Often, this is a Euclidean vector space, and in that space each vector represents a
single node in the network. We’ll focus on this case for now.</p>
<section id="why-embed-networks">
<h2>Why embed networks?<a class="headerlink" href="#why-embed-networks" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Embedding networks can be viewed as fitting the parameters of statistical models,
for example, a random dot product graph.</p></li>
<li><p>Embeddings can be useful for creating visualizations of networks.</p></li>
<li><p>Embeddings allow us to use a wide range of general machine learning techniques and
make them applicable for networks.</p></li>
</ul>
</section>
<section id="spectral-methods">
<h2>Spectral methods<a class="headerlink" href="#spectral-methods" title="Permalink to this headline">#</a></h2>
<p>A few classes ago when we discussed <a class="reference internal" href="random_graphs.html"><span class="doc std std-doc">random network models</span></a>, we
talked about how there was a method for estimating the parameters of the random dot product graph (RDPG) model. For simplicity, lets consider an undirected version of this model. Recall
what this means - the model is that the adjacency matrix <span class="math notranslate nohighlight">\(A\)</span> is sampled from a probability
matrix <span class="math notranslate nohighlight">\(P\)</span>, and that this <span class="math notranslate nohighlight">\(P\)</span> matrix is <em>low rank</em>. In other words, it can be written as</p>
<div class="math notranslate nohighlight">
\[P = X X^T\]</div>
<p>for some matrix, <span class="math notranslate nohighlight">\(X\)</span>, which we’ll call the <strong>latent position matrix</strong>. <span class="math notranslate nohighlight">\(X\)</span> is an <span class="math notranslate nohighlight">\(n \times d\)</span>
matrix, where <span class="math notranslate nohighlight">\(d\)</span> is the dimension of our model or the length of the latent position
vector of each node.</p>
<p>In practice, we never observe <span class="math notranslate nohighlight">\(X\)</span> - we observe the adjacency matrix <span class="math notranslate nohighlight">\(X\)</span>, and wish to
estimate <span class="math notranslate nohighlight">\(X\)</span> from it.</p>
<section id="low-rank-approximation">
<h3>Low-rank approximation<a class="headerlink" href="#low-rank-approximation" title="Permalink to this headline">#</a></h3>
<p>One fundamental concept in statistics and machine learning is that of a <a class="reference external" href="https://en.wikipedia.org/wiki/Low-rank_approximation"><strong>low-rank
decomposition</strong></a>. In general,
this means approximating some data matrix with a less complex while still preserving certain properties of the data. One fundamental tool in this field is the <a class="reference external" href="https://en.wikipedia.org/wiki/Singular_value_decomposition"><strong>singular value
decomposition (SVD)</strong></a>. If
you aren’t familiar with the SVD, I <em>highly</em> recommend learning more about it, as it is
one of the most important mathematical tools in science and engineering. I’ll briefly
state what it is here.</p>
</section>
<section id="singular-value-decomposition">
<h3>Singular value decomposition<a class="headerlink" href="#singular-value-decomposition" title="Permalink to this headline">#</a></h3>
<p>Let <span class="math notranslate nohighlight">\(M\)</span> be some <span class="math notranslate nohighlight">\(m \times n\)</span> real matrix with rank <span class="math notranslate nohighlight">\(r\)</span>. Then, this matrix can be
factorized as</p>
<div class="math notranslate nohighlight">
\[M = U \Sigma V^T\]</div>
<p>where these matrices have the following properties:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(U\)</span> is <span class="math notranslate nohighlight">\(m \times r\)</span> with orthonormal columns (i.e. <span class="math notranslate nohighlight">\(U^T U = I_{r}\)</span>, the <span class="math notranslate nohighlight">\(r \times r\)</span> identity)</p></li>
<li><p><span class="math notranslate nohighlight">\(V\)</span> is <span class="math notranslate nohighlight">\(n \times r\)</span> with orthonormal columns (i.e. <span class="math notranslate nohighlight">\(V^T V = I_{r}\)</span>)</p></li>
<li><p><span class="math notranslate nohighlight">\(\Sigma\)</span> is <span class="math notranslate nohighlight">\(r \times r\)</span> and diagonal, with elements on the diagonal in decreasing order</p></li>
</ul>
<p>The factorization above is called the singular value decomposition.</p>
<p>What do we call these different pieces of the decomposition?</p>
<ul class="simple">
<li><p>The columns of <span class="math notranslate nohighlight">\(U\)</span> are called the <strong>left singular vectors</strong>.</p></li>
<li><p>The columns of <span class="math notranslate nohighlight">\(V\)</span> are called the <strong>right singular vectors</strong>.</p></li>
<li><p>The elements on the diagonal of <span class="math notranslate nohighlight">\(\Sigma\)</span> are called the <strong>singular values</strong>.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If <span class="math notranslate nohighlight">\(M\)</span> is square and symmetric (e.g. the adjacency matrix for an undirected graph), note
that the left and the right singular vectors are the same, so we could write</p>
<div class="math notranslate nohighlight">
\[M = U \Sigma U^T\]</div>
<p>More commonly, it will be written as</p>
<div class="math notranslate nohighlight">
\[M = U D U^T\]</div>
<p>This is also known as an <strong>eigendecomposition</strong>. For this reason, you may see people use
these terms interchangably, in particular for undirected networks.</p>
</div>
</section>
<section id="eckart-young-mirsky-theorem">
<h3>Eckart-Young-Mirsky theorem<a class="headerlink" href="#eckart-young-mirsky-theorem" title="Permalink to this headline">#</a></h3>
<p>Why did we go to all of this trouble to decompose our matrix in this way? There are a
TON of different ways to see the value of the SVD - some are geometric, some are
statistical, and many more. Here we’ll consider one of these perspectives, which is that
of the low-rank decomposition described above.</p>
<p>Let’s say I hand you a matrix, <span class="math notranslate nohighlight">\(A\)</span>, which is some square real data matrix I observed (it doesn’t actually have to be square for the theorem to hold, though).
In almost all cases, this matrix is going to be of full rank - it will have as many
nonzero singular values as it has dimensions. Then I ask you to approximate this matrix,
using another matrix, <span class="math notranslate nohighlight">\(A_d\)</span>, which has rank at most <span class="math notranslate nohighlight">\(d\)</span>. I am going to measure how well
you approximate my matrix <span class="math notranslate nohighlight">\(A\)</span> in the following way:</p>
<div class="math notranslate nohighlight">
\[e = \|A - A_d\|_F\]</div>
<p>where <span class="math notranslate nohighlight">\(\| \cdot \|_F\)</span> is the matrix <a class="reference external" href="https://en.wikipedia.org/wiki/Matrix_norm#Frobenius_norm"><strong>Frobenius norm</strong></a>. The Frobenius norm is like the <span class="math notranslate nohighlight">\(l_2\)</span> or Euclidean norm for
vectors, but applied to a matrix. I simply sum up the squared values in the matrix, and
then take the square root of that sum.</p>
<p>What the <a class="reference external" href="https://en.wikipedia.org/wiki/Low-rank_approximation#Proof_of_Eckart%E2%80%93Young%E2%80%93Mirsky_theorem_(for_Frobenius_norm)">Eckart-Young-Mirsky theorem</a> says is that the best solution to the problem I posed above (i.e. the <span class="math notranslate nohighlight">\(A_d\)</span>
which minimizes <span class="math notranslate nohighlight">\(e\)</span>) is given by:</p>
<div class="math notranslate nohighlight">
\[A_d = U_d \Sigma_d V_d^T\]</div>
<p>where <span class="math notranslate nohighlight">\(U_d\)</span> is the matrix with only the first <span class="math notranslate nohighlight">\(d\)</span> left singular vectors of <span class="math notranslate nohighlight">\(A\)</span>, <span class="math notranslate nohighlight">\(V_d\)</span> is
defined likewise for the right singular vectors, and <span class="math notranslate nohighlight">\(\Sigma_d\)</span> is a <span class="math notranslate nohighlight">\(d \times d\)</span> matrix
with only the first <span class="math notranslate nohighlight">\(d\)</span> singular values on the diagonal. The decomposition in for <span class="math notranslate nohighlight">\(A_d\)</span>
above would be called a <strong>truncated singular value decomposition</strong> of <span class="math notranslate nohighlight">\(A\)</span>.</p>
</section>
<section id="adjacency-spectral-embedding">
<h3>Adjacency Spectral Embedding<a class="headerlink" href="#adjacency-spectral-embedding" title="Permalink to this headline">#</a></h3>
<p>Great, now lets turn back to our specific case of networks. Given everything we just
discussed, you may see where we’re headed.</p>
<p>Now, if I ask you to do a low-rank approximation of the adjacency matrix <span class="math notranslate nohighlight">\(A\)</span> of a network, you know what
to do (at least, if we care about the Frobenius norm of the difference).</p>
<p>For an undirected network, we’d have</p>
<div class="math notranslate nohighlight">
\[A_d = U_d \Sigma_d U_d^T\]</div>
<p>we can absorb the singular values into the vectors themselves</p>
<div class="math notranslate nohighlight">
\[X = U_d \Sigma_d^{1/2}\]</div>
<p>so that</p>
<div class="math notranslate nohighlight">
\[A_d =  U_d \Sigma_d U_d^T = U_d \Sigma_d^{1/2} \Sigma_d^{1/2} U_d^T = U_d \Sigma_d^{1/2} (U_d \Sigma_d^{1/2})^T = X X^T\]</div>
<p>For a directed network, we can do something similar</p>
<div class="math notranslate nohighlight">
\[A_d = U_d \Sigma_d V_d^T = X Y^T\]</div>
<p>where <span class="math notranslate nohighlight">\(X\)</span> has the same meaning as before, and <span class="math notranslate nohighlight">\(Y\)</span> is defined likewise for <span class="math notranslate nohighlight">\(V\)</span>.</p>
<p>Does this formula remind you of anything? It looks awfully similar to the formula for
the RDPG: <span class="math notranslate nohighlight">\(P = X Y^T\)</span>. It turns out that this process, which is called the
<strong>adjacency spectral embedding (ASE)</strong>, is a consistent estimator for the parameters <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>
in the RDPG setting. What “consistent” means in this setting is that is we had a network
generated from an RDPG, and then let the number of nodes in the network grow to infinity,
then the <span class="math notranslate nohighlight">\(\hat{X}\)</span> matrix we estimate via ASE would converge to the true latent position
matrix, <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p>Let’s see what this looks like in terms of implementation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">graspologic.datasets</span> <span class="kn">import</span> <span class="n">load_drosophila_right</span>
<span class="kn">from</span> <span class="nn">graspologic.utils</span> <span class="kn">import</span> <span class="n">binarize</span>

<span class="n">A</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">load_drosophila_right</span><span class="p">(</span><span class="n">return_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">A_bin</span> <span class="o">=</span> <span class="n">binarize</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">Vt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">A_bin</span><span class="p">)</span>

<span class="n">d</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">sigma_root</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">S</span><span class="p">[:</span><span class="n">d</span><span class="p">]))</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">U</span><span class="p">[:,</span> <span class="p">:</span><span class="n">d</span><span class="p">]</span> <span class="o">@</span> <span class="n">sigma_root</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">Vt</span><span class="o">.</span><span class="n">T</span><span class="p">[:,</span> <span class="p">:</span><span class="n">d</span><span class="p">]</span> <span class="o">@</span> <span class="n">sigma_root</span>
</pre></div>
</div>
</div>
</div>
<p>Pretty simple! We can use these estimates to reconstruct an estimate of the probability
matrix if we wanted to model the network as an RDPG.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">graspologic.plot</span> <span class="kn">import</span> <span class="n">heatmap</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">heatmap</span><span class="p">(</span>
    <span class="n">A_bin</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
    <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Adjacency matrix&quot;</span><span class="p">,</span>
    <span class="n">hier_label_fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">remove</span><span class="p">()</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">heatmap</span><span class="p">(</span>
    <span class="n">X</span> <span class="o">@</span> <span class="n">Y</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
    <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Probability matrix estimate&quot;</span><span class="p">,</span>
    <span class="n">hier_label_fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/embedding_5_0.png" src="_images/embedding_5_0.png" />
</div>
</div>
<p>In <code class="docutils literal notranslate"><span class="pre">graspologic</span></code>, this functionality is implemented under the <code class="docutils literal notranslate"><span class="pre">AdjacencySpectralEmbed</span></code>
estimator class. There are a few extra bells and whistles, but the core algorithm is
exactly the same as the one above - just an SVD of the adjacency matrix. Note that this
algorithm also works well for weighted networks, but we lose some of the interpretation
of the approximation matrix as a matrix of probabilities.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.embed</span> <span class="kn">import</span> <span class="n">AdjacencySpectralEmbed</span>

<span class="n">ase</span> <span class="o">=</span> <span class="n">AdjacencySpectralEmbed</span><span class="p">()</span>

<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">ase</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">ase.fit_transform()</span></code> returns a tuple <code class="docutils literal notranslate"><span class="pre">(X,</span> <span class="pre">Y)</span></code> if the graph is directed. Otherwise, it
just returns <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.plot</span> <span class="kn">import</span> <span class="n">pairplot</span>

<span class="n">pairplot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;seaborn.axisgrid.PairGrid at 0x144f27550&gt;
</pre></div>
</div>
<img alt="_images/embedding_9_1.png" src="_images/embedding_9_1.png" />
</div>
</div>
<p>This is a perfectly fine ASE - but note that the embedding above is somewhat dominated
by a few nodes.</p>
<div class="tip admonition">
<p class="admonition-title">Question</p>
<p>What do you think is special about the nodes which are most salient in the plot above?</p>
</div>
<p>The edge weights in this dataset cover a few orders of magnitude - there are a small
number of edges which have very high weights.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s1">&#39;talk&#39;</span><span class="p">)</span>

<span class="n">row_indices</span><span class="p">,</span> <span class="n">col_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>  <span class="c1"># gives me the location of each edge</span>

<span class="n">edges</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">row_indices</span><span class="p">,</span> <span class="n">col_indices</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">edges</span><span class="p">,</span> <span class="n">discrete</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[[</span><span class="s2">&quot;right&quot;</span><span class="p">,</span> <span class="s2">&quot;top&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Edge weight&quot;</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">edges</span><span class="p">,</span> <span class="n">discrete</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[[</span><span class="s2">&quot;right&quot;</span><span class="p">,</span> <span class="s2">&quot;top&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Edge weight&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Text(0.5, 0, &#39;Edge weight&#39;)]
</pre></div>
</div>
<img alt="_images/embedding_11_1.png" src="_images/embedding_11_1.png" />
</div>
</div>
<p>For spectral methods on weighted networks, we often find it useful to do an operation
called “pass-to-ranks.” This essentially ranks each edge from smallest to largest weight,
then replaces the edge weight by a normalized version of the rank. It has the effect of
putting edges closer to the same scale.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.utils</span> <span class="kn">import</span> <span class="n">pass_to_ranks</span>

<span class="n">ase</span> <span class="o">=</span> <span class="n">AdjacencySpectralEmbed</span><span class="p">()</span>

<span class="n">A_ptr</span> <span class="o">=</span> <span class="n">pass_to_ranks</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">ase</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">A_ptr</span><span class="p">)</span>

<span class="n">pairplot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;seaborn.axisgrid.PairGrid at 0x1491733d0&gt;
</pre></div>
</div>
<img alt="_images/embedding_13_1.png" src="_images/embedding_13_1.png" />
</div>
</div>
<p>For some applications, we don’t care about having a separate representation for each
node in terms of its inputs and outputs. We can simply concatenate the “out” and “in”
representations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">Z</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(213, 6)
</pre></div>
</div>
</div>
</div>
<p>Or, we can specify this behavior in <code class="docutils literal notranslate"><span class="pre">graspologic</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Z</span> <span class="o">=</span> <span class="n">AdjacencySpectralEmbed</span><span class="p">(</span><span class="n">concat</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">A_ptr</span><span class="p">)</span>
<span class="n">Z</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(213, 6)
</pre></div>
</div>
</div>
</div>
<p>We can also embed a matrix in sparse format, which will usually be faster for sparse
networks with more than a small number of nodes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">csr_matrix</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">AdjacencySpectralEmbed</span><span class="p">(</span><span class="n">concat</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">csr_matrix</span><span class="p">(</span><span class="n">A_ptr</span><span class="p">))</span>
<span class="n">Z</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(213, 6)
</pre></div>
</div>
</div>
</div>
</section>
<section id="laplacian-spectral-embedding">
<h3>Laplacian spectral embedding<a class="headerlink" href="#laplacian-spectral-embedding" title="Permalink to this headline">#</a></h3>
<p>Thus far, we’ve motivated our spectral approaches by talking about random dot product
graphs and matrix approximation. However, there’s a parallel way to arrive at some of
these ideas, in particular for a related algorithm called <strong>laplacian spectral embeddding (LSE)</strong>. This is the workhorse behind an old and popular method called <a class="reference external" href="https://en.wikipedia.org/wiki/Spectral_clustering">spectral clustering</a>.</p>
<p>Let’s consider an undirected network, with degree vector <span class="math notranslate nohighlight">\(k\)</span>. Let <span class="math notranslate nohighlight">\(D\)</span> be a diagonal
matrix with <span class="math notranslate nohighlight">\(k\)</span> on its diagonal. One version of the
Laplacian <span class="math notranslate nohighlight">\(L\)</span> (there are many) which is often called the unnormalized Laplacian, is just</p>
<div class="math notranslate nohighlight">
\[L = D - A\]</div>
<p>There is a TON of cool math surrounding these methods that we could talk about - for
instance, looking at the eigenvectors of the Laplacian matrix can perform a kind of
“spring layout” of the network, where each edge is treated as a spring, and the goal
is to arrange nodes to minimize the energy of this system. Another perspective is that eigenvectors of the Laplacian give an approximate solution to the <a class="reference external" href="https://en.wikipedia.org/wiki/Minimum_cut">min-cut problem</a>. If you are curious about the Laplacian and any of these perspectives, I
highly recommend looking at <span id="id1">Von Luxburg [<a class="reference internal" href="#id72" title="Ulrike Von Luxburg. A tutorial on spectral clustering. Statistics and computing, 17(4):395–416, 2007.">1</a>]</span>.</p>
<p>Briefly, I’ll just say that for a graph with multiple connected components, the
eigenvectors of the Laplacian turn out to be indicator functions for each of these
connected components. Let’s look at the eigenvectors for a graph with three connected
components.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">graspologic.simulations</span> <span class="kn">import</span> <span class="n">sbm</span>


<span class="k">def</span> <span class="nf">eig</span><span class="p">(</span><span class="n">A</span><span class="p">):</span>
    <span class="n">evals</span><span class="p">,</span> <span class="n">evecs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
    <span class="n">sort_inds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">evals</span><span class="p">)</span>
    <span class="n">evals</span> <span class="o">=</span> <span class="n">evals</span><span class="p">[</span><span class="n">sort_inds</span><span class="p">]</span>
    <span class="n">evecs</span> <span class="o">=</span> <span class="n">evecs</span><span class="p">[:,</span> <span class="n">sort_inds</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">evals</span><span class="p">,</span> <span class="n">evecs</span>


<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]])</span>
<span class="n">A</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">sbm</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">B</span><span class="p">,</span> <span class="n">return_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">heatmap</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="n">degrees</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">degrees</span><span class="p">)</span>
<span class="n">L</span> <span class="o">=</span> <span class="n">D</span> <span class="o">-</span> <span class="n">A</span>
<span class="n">evals</span><span class="p">,</span> <span class="n">evecs</span> <span class="o">=</span> <span class="n">eig</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">evecs</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">evecs</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])),</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;Index&quot;</span><span class="p">))</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;Eigenvector element&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Text(0, 0.5, &#39;Eigenvector element&#39;)]
</pre></div>
</div>
<img alt="_images/embedding_21_1.png" src="_images/embedding_21_1.png" />
<img alt="_images/embedding_21_2.png" src="_images/embedding_21_2.png" />
</div>
</div>
<p>What if the graph doesn’t have multiple connected components, but has a <em>fuzzy</em> version
of this - i.e. some parts of the graph that are mostly disconnected from the rest?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]])</span>
<span class="n">A</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">sbm</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">B</span><span class="p">,</span> <span class="n">return_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">heatmap</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="n">degrees</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">degrees</span><span class="p">)</span>
<span class="n">L</span> <span class="o">=</span> <span class="n">D</span> <span class="o">-</span> <span class="n">A</span>
<span class="n">evals</span><span class="p">,</span> <span class="n">evecs</span> <span class="o">=</span> <span class="n">eig</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">evecs</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">evecs</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])),</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;Index&quot;</span><span class="p">))</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;Eigenvector element&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Text(0, 0.5, &#39;Eigenvector element&#39;)]
</pre></div>
</div>
<img alt="_images/embedding_23_1.png" src="_images/embedding_23_1.png" />
<img alt="_images/embedding_23_2.png" src="_images/embedding_23_2.png" />
</div>
</div>
<div class="admonition-question admonition">
<p class="admonition-title">Question</p>
<p>Why does the first eigenvector look like it does, where all nodes seem to be equal?</p>
</div>
<p>Hopefully you can see why this kind of analysis could be useful, and might relate to
the idea of spectral clustering I mentioned before. By analyzing the eigendecomposition
of the Laplacian (say, by clustering it), often we can understand meaningful partitions
of a network.</p>
<p>Let’s look at how this type of analysis looks on the C. elegans connectome from
<span id="id2">Cook <em>et al.</em> [<a class="reference internal" href="#id71" title="Steven J Cook, Travis A Jarrell, Christopher A Brittin, Yi Wang, Adam E Bloniarz, Maksim A Yakovlev, Ken CQ Nguyen, Leo T-H Tang, Emily A Bayer, Janet S Duerr, and others. Whole-animal connectomes of both caenorhabditis elegans sexes. Nature, 571(7763):63–71, 2019.">2</a>]</span>.</p>
<figure class="align-default" id="id79">
<img alt="_images/c-elegans.png" src="_images/c-elegans.png" />
<figcaption>
<p><span class="caption-number">Fig. 9 </span><span class="caption-text">Network diagram and 3D position of neurons in the C. elegans male connectome. Figure
from <span id="id3">Cook <em>et al.</em> [<a class="reference internal" href="#id71" title="Steven J Cook, Travis A Jarrell, Christopher A Brittin, Yi Wang, Adam E Bloniarz, Maksim A Yakovlev, Ken CQ Nguyen, Leo T-H Tang, Emily A Bayer, Janet S Duerr, and others. Whole-animal connectomes of both caenorhabditis elegans sexes. Nature, 571(7763):63–71, 2019.">2</a>]</span>.</span><a class="headerlink" href="#id79" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_path</span> <span class="o">=</span> <span class="s2">&quot;networks-course/data/celegans/male_chem_A_self_undirected.csv&quot;</span>
<span class="n">meta_path</span> <span class="o">=</span> <span class="s2">&quot;networks-course/data/celegans/master_cells.csv&quot;</span>
<span class="n">cells_path</span> <span class="o">=</span> <span class="s2">&quot;networks-course/data/celegans/male_chem_self_cells.csv&quot;</span>
<span class="n">adj</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">meta</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">meta_path</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">cells</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">cells_path</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">meta</span> <span class="o">=</span> <span class="n">meta</span><span class="o">.</span><span class="n">reindex</span><span class="p">(</span><span class="n">cells</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">adj</span><span class="o">.</span><span class="n">values</span>

<span class="n">degrees</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">degrees</span><span class="p">)</span>
<span class="n">L</span> <span class="o">=</span> <span class="n">D</span> <span class="o">-</span> <span class="n">A</span>
<span class="n">evals</span><span class="p">,</span> <span class="n">evecs</span> <span class="o">=</span> <span class="n">eig</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">evecs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">evecs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])),</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Index (node)&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Value in eigenvector&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Text(0.5, 0, &#39;Index (node)&#39;), Text(0, 0.5, &#39;Value in eigenvector&#39;)]
</pre></div>
</div>
<img alt="_images/embedding_27_1.png" src="_images/embedding_27_1.png" />
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Question</p>
<p>What do you think is different or special about the nodes that are well represented
in this eigenvector?</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">hue</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[</span><span class="mi">6</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span>
    <span class="n">y</span><span class="o">=</span><span class="n">evecs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">evecs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])),</span> <span class="n">hue</span><span class="o">=</span><span class="n">hue</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">15</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Index (node)&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Value in eigenvector&quot;</span><span class="p">)</span>

<span class="c1">#%%</span>
<span class="c1"># janky code to look at the adjacency matrix sorted this way.</span>
<span class="c1"># not sure why there is a nan</span>
<span class="n">is_pharynx</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">meta</span><span class="p">[</span><span class="mi">6</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">is_pharynx</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">val</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;pharynx&quot;</span><span class="p">,</span> <span class="s2">&quot;nonpharynx&quot;</span><span class="p">,</span> <span class="s2">&quot;linker&quot;</span><span class="p">]:</span>
        <span class="n">is_pharynx</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;nonpharynx&quot;</span>
<span class="n">heatmap</span><span class="p">(</span>
    <span class="n">A</span><span class="p">,</span> <span class="n">inner_hier_labels</span><span class="o">=</span><span class="n">is_pharynx</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="s2">&quot;simple-nonzero&quot;</span><span class="p">,</span> <span class="n">hier_label_fontsize</span><span class="o">=</span><span class="mi">12</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:&gt;
</pre></div>
</div>
<img alt="_images/embedding_29_1.png" src="_images/embedding_29_1.png" />
<img alt="_images/embedding_29_2.png" src="_images/embedding_29_2.png" />
</div>
</div>
<p>In practice, we often use LSE much like ASE. We can use the implementation in
<code class="docutils literal notranslate"><span class="pre">graspologic</span></code>, which is very similar to the above but uses a slightly different version
of the Laplacian. I always recommend using the <em>regularized</em> version of the Laplacian,
which does a better job of dealing with nodes with highly varying degrees.
Again, I recommend trying the the pass-to-ranks method if working on a weighted network.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.embed</span> <span class="kn">import</span> <span class="n">LaplacianSpectralEmbed</span>

<span class="n">lse</span> <span class="o">=</span> <span class="n">LaplacianSpectralEmbed</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">form</span><span class="o">=</span><span class="s2">&quot;R-DAD&quot;</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">lse</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">pass_to_ranks</span><span class="p">(</span><span class="n">A</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pairplot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">is_pharynx</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;seaborn.axisgrid.PairGrid at 0x1495ee4f0&gt;
</pre></div>
</div>
<img alt="_images/embedding_32_1.png" src="_images/embedding_32_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pairplot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">meta</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s2">&quot;unk&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;seaborn.axisgrid.PairGrid at 0x1472ce460&gt;
</pre></div>
</div>
<img alt="_images/embedding_33_1.png" src="_images/embedding_33_1.png" />
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Question</p>
<p>Notice the “spokes” or dense lines in this plot - what might those represent?</p>
</div>
</section>
<section id="two-truths">
<h3>Two truths<a class="headerlink" href="#two-truths" title="Permalink to this headline">#</a></h3>
<p>So, why use LSE or ASE over the other? This is a good illustration of one important
point about network embeddings - usually, one method isn’t necessarily better or worse
than another, they’re simply different. Often, different network embedding methods
will capture different aspects of network structure. It will be up to you to choose or
experiment and see which is best for your application.</p>
<p>In a recent paper, <span id="id4">Priebe <em>et al.</em> [<a class="reference internal" href="#id73" title="Carey E Priebe, Youngser Park, Joshua T Vogelstein, John M Conroy, Vince Lyzinski, Minh Tang, Avanti Athreya, Joshua Cape, and Eric Bridgeford. On a two-truths phenomenon in spectral graph clustering. Proceedings of the National Academy of Sciences, 116(13):5995–6000, 2019.">3</a>]</span> showed that when applied to a dataset of human brain networks, ASE and LSE both captured meaningful, but different,aspects of the network. The LSE representation captured the left hemisphere/right hemisphere split in the human brain, while the ASE representation captured the grey matter/white matter difference.</p>
<figure class="align-default" id="id80">
<img alt="_images/two-truths.jpeg" src="_images/two-truths.jpeg" />
<figcaption>
<p><span class="caption-number">Fig. 10 </span><span class="caption-text">Illustration of a “Two truths” phenomenon in spectral graph clustering. Figure from <span id="id5">Priebe <em>et al.</em> [<a class="reference internal" href="#id73" title="Carey E Priebe, Youngser Park, Joshua T Vogelstein, John M Conroy, Vince Lyzinski, Minh Tang, Avanti Athreya, Joshua Cape, and Eric Bridgeford. On a two-truths phenomenon in spectral graph clustering. Proceedings of the National Academy of Sciences, 116(13):5995–6000, 2019.">3</a>]</span>.</span><a class="headerlink" href="#id80" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="deepwalk-node2vec">
<h2>DeepWalk / Node2Vec<a class="headerlink" href="#deepwalk-node2vec" title="Permalink to this headline">#</a></h2>
<p>Now, we’ll switch gears and talk about network embedding methods that are not based on
spectral decompositions.</p>
<section id="word2vec">
<h3>Word2vec<a class="headerlink" href="#word2vec" title="Permalink to this headline">#</a></h3>
<p>To start understanding DeepWalk and Node2Vec, it’s most helpful to take a brief detour
and look at Word2Vec <span id="id6">[<a class="reference internal" href="#id67" title="Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781, 2013.">4</a>]</span>. If you are curious about Word2Vec,
you can find a fairly accessible introduction at <a class="reference external" href="http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/">Chris McCormick’s blog</a>.</p>
<p><strong>Word2Vec</strong> is an unsupervised language model developed by researchers at Google. The first
key idea, which is very common in natural language processing (NLP), is that we can
train a model (in this case a neural network) on a “fake” supervised learning task. In
other words, we take a huge dataset without labels (e.g. all of the text you can find
on the internet, say) and make a labeled dataset from it. This is done by moving a
sliding window over each sentence, and creating (<em>center word</em>, <em>surrounding word</em>)
pairs. The task, then, is to predict the surrounding words from the word in the center.
In this way, we are training a model to understand the <em>context</em> of the center word
as it is used in language.</p>
<figure class="align-default" id="id81">
<img alt="_images/w2v-training-data.png" src="_images/w2v-training-data.png" />
<figcaption>
<p><span class="caption-number">Fig. 11 </span><span class="caption-text">Diagram showing how source text is converted to training data for the Word2Vec / Skip-gram
model. Figure from <a class="reference external" href="http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/">Chris McCormick’s blog</a>.</span><a class="headerlink" href="#id81" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>What does this model actually look like? In the case of Word2Vec, it is simply a 2-layer
neural network. We wont talk much about the details of neural networks for the purposes
of this course, but the key idea is that neural networks are functions which we train
(via sets of labeled data) to predict some output based on some input. Neural networks
do so by taking input that can be represented mathematically somehow (e.g. as a vector),
and more or less performing a series of matrix-vector multiplications followed by some nonlinearities to reach an output which usually represents the probability of some
particular output.</p>
<figure class="align-default" id="id82">
<img alt="_images/word2vec-skip-gram.png" src="_images/word2vec-skip-gram.png" />
<figcaption>
<p><span class="caption-number">Fig. 12 </span><span class="caption-text">Diagram showing the architecture of Word2Vec. Figure from <a class="reference external" href="https://lilianweng.github.io/lil-log/2017/10/15/learning-word-embedding.html">here</a>.</span><a class="headerlink" href="#id82" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Note that the first part of this neural network architecture is just a weight, which
maps each word in our vocabulary to some hidden representation which is useful for
predicting the context of a word. After training, this weight matrix is used as the
<em>embedding</em> for each word in our vocabulary.</p>
</section>
<section id="from-word2vec-to-deepwalk">
<h3>From Word2Vec to DeepWalk<a class="headerlink" href="#from-word2vec-to-deepwalk" title="Permalink to this headline">#</a></h3>
<p>Given the success of Word2Vec (as of 2022 I saw it had &gt;24,000 citations), it made sense
to wonder whether this fairly simple tool could be applied to other contexts, like
networks.</p>
<p>One “sequence on a network” that keeps coming up for us is random walks (see <a class="reference internal" href="centrality.html"><span class="doc std std-doc">Centrality measures</span></a>). So, what if we generate a ton of random walks on our network, and then trained a
Word2Vec model to predict context nodes from the nodes in the center of a window.</p>
<figure class="align-default" id="id83">
<img alt="_images/deepwalk.png" src="_images/deepwalk.png" />
<figcaption>
<p><span class="caption-number">Fig. 13 </span><span class="caption-text">Overview of DeepWalk. Figure from <span id="id7">Perozzi <em>et al.</em> [<a class="reference internal" href="#id68" title="Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. Deepwalk: online learning of social representations. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, 701–710. 2014.">5</a>]</span></span><a class="headerlink" href="#id83" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="from-deepwalk-to-node2vec">
<h3>From DeepWalk to Node2Vec<a class="headerlink" href="#from-deepwalk-to-node2vec" title="Permalink to this headline">#</a></h3>
<p>Node2Vec further modified the algorithm from DeepWalk, mainly by modifying the way that
random walks are generated. Rather than being true random walks, these paths through
the network are biased to be more or less likely to travel in the neighborhood they came
from based on some user provided parameters. The authors claimed that adjusting these
parameters based on the application let them find more useful representations for
some datasets, but this result has been debated somewhat.</p>
<figure class="align-default" id="id84">
<img alt="_images/n2v-modification.png" src="_images/n2v-modification.png" />
<figcaption>
<p><span class="caption-number">Fig. 14 </span><span class="caption-text">Modification to random walks from Node2Vec. Figure from <span id="id8">Grover and Leskovec [<a class="reference internal" href="#id69" title="Aditya Grover and Jure Leskovec. Node2vec: scalable feature learning for networks. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining, 855–864. 2016.">6</a>]</span></span><a class="headerlink" href="#id84" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="running-node2vec">
<h3>Running Node2Vec<a class="headerlink" href="#running-node2vec" title="Permalink to this headline">#</a></h3>
<p>We can learn a Node2Vec embedding easily using <code class="docutils literal notranslate"><span class="pre">graspologic</span></code> - note that many other
implementations are available. Under the hood, this one uses <code class="docutils literal notranslate"><span class="pre">gensim</span></code> to create a
Word2Vec model. To start, let’s load in a dataset.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>I originally grabbed the <a class="reference external" href="https://networks.skewed.de/net/cora">Cora dataset from Netzschleuder</a>,
but the .csv didn’t have labels, and also had far more nodes than I usually see for the
Cora dataset.</p>
<p>I honestly don’t know which is most correct - this is why it is always good to go back
to the original data source.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>

<span class="n">g</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">read_edgelist</span><span class="p">(</span>
    <span class="s2">&quot;networks-course/data/cora/edges.csv&quot;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="p">,</span> <span class="n">create_using</span><span class="o">=</span><span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span>
<span class="p">)</span>

<span class="nb">len</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>  <span class="c1"># number of nodes</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>23166
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">graspologic.embed</span> <span class="kn">import</span> <span class="n">node2vec_embed</span>

<span class="n">node2vec_embedding</span><span class="p">,</span> <span class="n">node_labels</span> <span class="o">=</span> <span class="n">node2vec_embed</span><span class="p">(</span>
    <span class="n">g</span><span class="p">,</span> <span class="n">num_walks</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">walk_length</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">inout_hyperparameter</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">return_hyperparameter</span><span class="o">=</span><span class="mf">1.0</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/bpedigo/JHU_code/bilateral/graspologic/graspologic/utils/utils.py:1130: UserWarning: Graph has at least one unweighted edge using weight_attribute &quot;weight&quot;. Defaulting unweighted edges to &quot;1.0&quot;
  warnings.warn(
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">node2vec_embedding</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(23166, 128)
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title">Question</p>
<p>Do you expect the output from two runs of <code class="docutils literal notranslate"><span class="pre">node2vec_embed</span></code> to be the same if they are
run on the same dataset? Why or why not?</p>
</div>
<p>So, we now have a 128-dimensional vector associated with each node in our network. It
can be useful to use UMAP <span id="id9">[<a class="reference internal" href="#id70" title="Leland McInnes, John Healy, and James Melville. Umap: uniform manifold approximation and projection for dimension reduction. arXiv preprint arXiv:1802.03426, 2018.">7</a>]</span> or other dimensionality reduction
techniques to further compress these vectors into a 2D plot.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">umap</span> <span class="kn">import</span> <span class="n">UMAP</span>

<span class="n">umapper</span> <span class="o">=</span> <span class="n">UMAP</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">)</span>
<span class="n">umap_node2vec_embedding</span> <span class="o">=</span> <span class="n">umapper</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">node2vec_embedding</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">umap_node2vec_embedding</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="n">y</span><span class="o">=</span><span class="n">umap_node2vec_embedding</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
    <span class="n">s</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/embedding_45_0.png" src="_images/embedding_45_0.png" />
</div>
</div>
<p>Now let’s try using the Cora dataset, which is a network of academic citations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">edge_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;./networks-course/data/cora_nr/cora.edges&quot;</span><span class="p">)</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">from_pandas_edgelist</span><span class="p">(</span><span class="n">edge_df</span><span class="p">,</span> <span class="n">create_using</span><span class="o">=</span><span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">,</span> <span class="n">edge_attr</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">edges</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2708
5278
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">node2vec_embedding</span><span class="p">,</span> <span class="n">node_ids</span> <span class="o">=</span> <span class="n">node2vec_embed</span><span class="p">(</span>
    <span class="n">g</span><span class="p">,</span>
    <span class="n">dimensions</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">num_walks</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">walk_length</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">inout_hyperparameter</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
    <span class="n">return_hyperparameter</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
    <span class="n">random_seed</span><span class="o">=</span><span class="mi">8888</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/bpedigo/JHU_code/bilateral/graspologic/graspologic/utils/utils.py:1130: UserWarning: Graph has at least one unweighted edge using weight_attribute &quot;weight&quot;. Defaulting unweighted edges to &quot;1.0&quot;
  warnings.warn(
WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words&#39; for smoother alpha decay
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">node_ids</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1, 9, 436, 545, 4, 198, 464, 602, 5, 171]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nodes</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;networks-course/data/cora_nr/cora.node_labels&quot;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">nodes</span> <span class="o">=</span> <span class="n">nodes</span><span class="o">.</span><span class="n">reindex</span><span class="p">(</span><span class="n">node_ids</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">umapper</span> <span class="o">=</span> <span class="n">UMAP</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">,</span> <span class="n">min_dist</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">888</span><span class="p">)</span>
<span class="n">umap_node2vec_embedding</span> <span class="o">=</span> <span class="n">umapper</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">node2vec_embedding</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nodes</span><span class="p">[</span><span class="s2">&quot;umap_0&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">umap_node2vec_embedding</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">nodes</span><span class="p">[</span><span class="s2">&quot;umap_1&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">umap_node2vec_embedding</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">nodes</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nodes</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>  <span class="c1"># for seaborn</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_context</span><span class="p">(</span><span class="s2">&quot;talk&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">nodes</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;umap_0&quot;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s2">&quot;umap_1&quot;</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
    <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">,</span>
    <span class="n">s</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/embedding_53_0.png" src="_images/embedding_53_0.png" />
</div>
</div>
<p>You can also use this representation to make a network layout at the same time, which
is something we often do.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">adj</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_scipy_sparse_matrix</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">nodelist</span><span class="o">=</span><span class="n">node_ids</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">graspologic.plot</span> <span class="kn">import</span> <span class="n">networkplot</span>

<span class="n">nodes</span><span class="p">[</span><span class="s2">&quot;degree&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">adj</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">networkplot</span><span class="p">(</span>
    <span class="n">adj</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;umap_0&quot;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s2">&quot;umap_1&quot;</span><span class="p">,</span>
    <span class="n">node_data</span><span class="o">=</span><span class="n">nodes</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(),</span>
    <span class="n">node_hue</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">,</span>
    <span class="n">node_size</span><span class="o">=</span><span class="s2">&quot;degree&quot;</span><span class="p">,</span>
    <span class="n">node_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">200</span><span class="p">),</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
    <span class="n">edge_linewidth</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">edge_alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/embedding_55_0.png" src="_images/embedding_55_0.png" />
</div>
</div>
</section>
</section>
<section id="applications-using-embeddings">
<h2>Applications using embeddings<a class="headerlink" href="#applications-using-embeddings" title="Permalink to this headline">#</a></h2>
<section id="recommendation">
<h3>Recommendation<a class="headerlink" href="#recommendation" title="Permalink to this headline">#</a></h3>
<p>One common application for embeddings is recommender systems - lets say we have a network,
and want to say something about what other nodes are most similar to a given node. Since
we have a <span class="math notranslate nohighlight">\(d\)</span>-dimensional representation which represents something about the role of
each node in our network, we can use this to simply look up nearest neighbors in this
space.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">NearestNeighbors</span>

<span class="n">nn</span> <span class="o">=</span> <span class="n">NearestNeighbors</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;euclidean&quot;</span><span class="p">)</span>
<span class="n">nn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">node2vec_embedding</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>NearestNeighbors(metric=&#39;euclidean&#39;, n_neighbors=6)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">query_node</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">dists</span><span class="p">,</span> <span class="n">neighbor_indices</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">kneighbors</span><span class="p">(</span>
    <span class="n">node2vec_embedding</span><span class="p">[</span><span class="n">query_node</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">neighbor_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">neighbor_indices</span><span class="p">)</span>
<span class="n">neighbor_indices</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 0,  2,  1, 29,  3, 18])
</pre></div>
</div>
</div>
</div>
<p>We can go back to our earlier visualization and look at the nodes which are picked as
“most similar.”</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">networkplot</span><span class="p">(</span>
    <span class="n">adj</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;umap_0&quot;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s2">&quot;umap_1&quot;</span><span class="p">,</span>
    <span class="n">node_data</span><span class="o">=</span><span class="n">nodes</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(),</span>
    <span class="n">node_hue</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">,</span>
    <span class="n">node_size</span><span class="o">=</span><span class="s2">&quot;degree&quot;</span><span class="p">,</span>
    <span class="n">node_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">70</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span>
    <span class="n">edge_linewidth</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">edge_alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">get_location</span><span class="p">(</span><span class="n">node_index</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">nodes</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">node_index</span><span class="p">][[</span><span class="s2">&quot;umap_0&quot;</span><span class="p">,</span> <span class="s2">&quot;umap_1&quot;</span><span class="p">]])</span>


<span class="n">center</span> <span class="o">=</span> <span class="n">get_location</span><span class="p">(</span><span class="n">query_node</span><span class="p">)</span>
<span class="n">pad</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="n">center</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">pad</span><span class="p">,</span> <span class="n">center</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">pad</span><span class="p">),</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="n">center</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">pad</span><span class="p">,</span> <span class="n">center</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">pad</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">figure</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">annotate</span><span class="p">(</span><span class="n">node_index</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">ax</span><span class="p">):</span>
    <span class="n">xy</span> <span class="o">=</span> <span class="n">get_location</span><span class="p">(</span><span class="n">node_index</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span>
        <span class="n">text</span><span class="p">,</span>
        <span class="n">xy</span><span class="p">,</span>
        <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">30</span><span class="p">),</span>
        <span class="n">textcoords</span><span class="o">=</span><span class="s2">&quot;offset points&quot;</span><span class="p">,</span>
        <span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">arrowstyle</span><span class="o">=</span><span class="s2">&quot;-&gt;&quot;</span><span class="p">),</span>
    <span class="p">)</span>


<span class="n">annotate</span><span class="p">(</span><span class="n">query_node</span><span class="p">,</span> <span class="s2">&quot;Query node&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">node_index</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">neighbor_indices</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
    <span class="n">annotate</span><span class="p">(</span><span class="n">node_index</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/embedding_61_0.png" src="_images/embedding_61_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_neighbor_query</span><span class="p">(</span><span class="n">query_node</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="n">dists</span><span class="p">,</span> <span class="n">neighbor_indices</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">kneighbors</span><span class="p">(</span>
        <span class="n">node2vec_embedding</span><span class="p">[</span><span class="n">query_node</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="n">neighbor_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">neighbor_indices</span><span class="p">)</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">networkplot</span><span class="p">(</span>
        <span class="n">adj</span><span class="p">,</span>
        <span class="n">x</span><span class="o">=</span><span class="s2">&quot;umap_0&quot;</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="s2">&quot;umap_1&quot;</span><span class="p">,</span>
        <span class="n">node_data</span><span class="o">=</span><span class="n">nodes</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(),</span>
        <span class="n">node_hue</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">,</span>
        <span class="n">node_size</span><span class="o">=</span><span class="s2">&quot;degree&quot;</span><span class="p">,</span>
        <span class="n">node_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">70</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span>
        <span class="n">edge_linewidth</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
        <span class="n">edge_alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>

    <span class="n">center</span> <span class="o">=</span> <span class="n">get_location</span><span class="p">(</span><span class="n">query_node</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
        <span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="n">center</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">pad</span><span class="p">,</span> <span class="n">center</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">pad</span><span class="p">),</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="n">center</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">pad</span><span class="p">,</span> <span class="n">center</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">pad</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">figure</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">)</span>

    <span class="n">annotate</span><span class="p">(</span><span class="n">query_node</span><span class="p">,</span> <span class="s2">&quot;Query node&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">node_index</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">neighbor_indices</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
        <span class="n">annotate</span><span class="p">(</span><span class="n">node_index</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">ax</span>


<span class="n">nn</span> <span class="o">=</span> <span class="n">NearestNeighbors</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;euclidean&quot;</span><span class="p">)</span>
<span class="n">nn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">node2vec_embedding</span><span class="p">)</span>

<span class="n">plot_neighbor_query</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="n">plot_neighbor_query</span><span class="p">(</span><span class="mi">700</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">plot_neighbor_query</span><span class="p">(</span><span class="mi">2210</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;AxesSubplot:xlabel=&#39;umap_0&#39;, ylabel=&#39;umap_1&#39;&gt;
</pre></div>
</div>
<img alt="_images/embedding_62_1.png" src="_images/embedding_62_1.png" />
<img alt="_images/embedding_62_2.png" src="_images/embedding_62_2.png" />
<img alt="_images/embedding_62_3.png" src="_images/embedding_62_3.png" />
</div>
</div>
<p>Note that it can be difficult to interpret exactly what this recommendation is based on.
For this particular example and the Node2Vec/DeepWalk settings we were using, it looks
like we found nodes that are in the local neighborhood of the query, which is perfectly
reasonable for some applications. With other parameters though, we might get something
very different.</p>
</section>
<section id="clustering">
<h3>Clustering<a class="headerlink" href="#clustering" title="Permalink to this headline">#</a></h3>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>TODO</p>
</div>
</section>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">#</a></h2>
<div class="docutils container" id="id10">
<dl class="citation">
<dt class="label" id="id72"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Ulrike Von Luxburg. A tutorial on spectral clustering. <em>Statistics and computing</em>, 17(4):395–416, 2007.</p>
</dd>
<dt class="label" id="id71"><span class="brackets">2</span><span class="fn-backref">(<a href="#id2">1</a>,<a href="#id3">2</a>)</span></dt>
<dd><p>Steven J Cook, Travis A Jarrell, Christopher A Brittin, Yi Wang, Adam E Bloniarz, Maksim A Yakovlev, Ken CQ Nguyen, Leo T-H Tang, Emily A Bayer, Janet S Duerr, and others. Whole-animal connectomes of both caenorhabditis elegans sexes. <em>Nature</em>, 571(7763):63–71, 2019.</p>
</dd>
<dt class="label" id="id73"><span class="brackets">3</span><span class="fn-backref">(<a href="#id4">1</a>,<a href="#id5">2</a>)</span></dt>
<dd><p>Carey E Priebe, Youngser Park, Joshua T Vogelstein, John M Conroy, Vince Lyzinski, Minh Tang, Avanti Athreya, Joshua Cape, and Eric Bridgeford. On a two-truths phenomenon in spectral graph clustering. <em>Proceedings of the National Academy of Sciences</em>, 116(13):5995–6000, 2019.</p>
</dd>
<dt class="label" id="id67"><span class="brackets"><a class="fn-backref" href="#id6">4</a></span></dt>
<dd><p>Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector space. <em>arXiv preprint arXiv:1301.3781</em>, 2013.</p>
</dd>
<dt class="label" id="id68"><span class="brackets"><a class="fn-backref" href="#id7">5</a></span></dt>
<dd><p>Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. Deepwalk: online learning of social representations. In <em>Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</em>, 701–710. 2014.</p>
</dd>
<dt class="label" id="id69"><span class="brackets"><a class="fn-backref" href="#id8">6</a></span></dt>
<dd><p>Aditya Grover and Jure Leskovec. Node2vec: scalable feature learning for networks. In <em>Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining</em>, 855–864. 2016.</p>
</dd>
<dt class="label" id="id70"><span class="brackets"><a class="fn-backref" href="#id9">7</a></span></dt>
<dd><p>Leland McInnes, John Healy, and James Melville. Umap: uniform manifold approximation and projection for dimension reduction. <em>arXiv preprint arXiv:1802.03426</em>, 2018.</p>
</dd>
</dl>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="community_detection.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Community detection</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="graph_matching.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Graph matching</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Benjamin D. Pedigo<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>